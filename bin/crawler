#!/usr/bin/env ruby
# coding: UTF-8

require 'optparse'
require 'resque'
require 'resque-scheduler'
require 'time'
require 'sengi'

@options = {
	'queue' => false,
	'serial' => false,
	'relative' => false,
	'debug' => false,
}
opts = OptionParser.new do |o|
	o.banner = 'Usage: crawler [options] <url...>'
	o.separator('')
	
	o.on('-q', '--queue', 'Enqueue a URL.') do
		@options['queue'] = true
	end
	
	o.on('-s', '--serial', 'Schedule the URLs serial.') do
		# Set this option to true to schedule the URLs serial.
		# The Redis key 'urls:schedule:last' will be used to store the last
		# used schedule time and URL_DELAY will be added to create a new
		# schedule time for the new URL.
		# Otherwise if this option isn't used URL_DELAY will be added
		# to the current time.
		@options['serial'] = true
	end
	
	o.on('-r', '--relative', 'Follow only relative links.') do
		# And also URLs with the same host.
		@options['relative'] = true
	end
	
	o.on('-f', '--force', 'Force a URL to be requested.') do
		@options['force'] = true
	end
	
	o.on('-d', 'Debug') do
		@options['debug'] = true
	end
	
	o.on_tail('-h', '--help', 'Show this message.') do
		puts o
		puts
		exit 3
	end
end
ARGV << '-h' if ARGV.count == 0
urls = opts.parse(ARGV)

Resque.redis = '127.0.0.1:7000'
urls.each_with_index do |url, index|
	if @options['queue']
		Resque.enqueue(TheFox::Sengi::CrawlerWorker, url, @options)
	else
		TheFox::Sengi::CrawlerWorker.perform(url, @options)
	end
end
